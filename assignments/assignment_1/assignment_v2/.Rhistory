add.to.row = list(list(-1,nrow(.)),
c(" & \\multicolumn{2}{c}{1980-1989} &
\\multicolumn{2}{c}{1990-1999} &
\\multicolumn{2}{c}{2000-2009} &
\\multicolumn{2}{c}{after 2010} &
\\multicolumn{2}{c}{All Periods}  \\\\
\\cmidrule(rl){2-3} \\cmidrule(rl){4-5} \\cmidrule(rl){6-7} \\cmidrule(rl){8-9} \\cmidrule(rl){10-11}",
"\\midrule  \\multicolumn{11}{L{14cm}}{{\\tiny \\textbf{Note: } This table reports our measures for coherence and specialization of the clusters of research areas, and their development over time. In detail, it reports the whitin-cluster density, the between cluster density, and the GINI coefficient of the edgeweights from every cluster to the remaining ones. P1:1980-1989, P2:1990-1999, P3:2000-2009, P4:2010-2017.}} \\\\") ) )
rm(list=ls())
source("00_parameters.r")
ra.names <- readRDS("temp/names_art.RDS") %>%
bind_cols(com =., ra.name = com.names.bib.short)
plot <- readRDS("temp/art_com_p.RDS")
D <- readRDS("temp/art_com_div_int.RDS")
plot %<>% left_join(D %>% select(com, P, coh.int, div.int), by = c("com", "P")) %>%
replace_na(list(coh.int = 0, div.int = 0))
plot %<>%
arrange(com, P) %>%
group_by(com) %>% mutate(growth = (n+1) / (n.cum+1) ) %>% ungroup() %>%
mutate(P = factor(P)) %>%
mutate(P = revalue(P, c("1" = "until 1989", "2" = "1990-1999", "3"  = "2000-2009", "4"  = "2010-2018"))) %>%
filter(n.cum >= 1) %>%
left_join(ra.names, by = "com") %>%
rename(Research.Area = ra.name)
# Cosmetics
plot[plot$P == "1990-1999" & plot$com == "ART07", "coh.int"] <- 0.026
ggplot(plot, aes(x =  coh.int, y = div.int, size = n.cum, colour = growth)) +
geom_point(alpha = 0.9) +
geom_text(aes(label = Research.Area), hjust = 0, vjust = 0, size = 4, color = "black") +
theme(legend.direction = "horizontal", legend.position = "bottom") +
#  coord_cartesian(xlim = c(0.0,0.026), ylim = c(0.0,0.41)) + #
labs(x = "Coherence of research area", y = "Diversity  of research area") +
facet_wrap(~ P, nrow=2)
ggsave("coherence_dev.pdf", path ="output/figures/", width=7.0, height=8.0, units="in"); graphics.off()
ggplot(plot, aes(x =  coh.int, y = div.int, size = n.cum, colour = growth)) +
geom_point(alpha = 0.9) +
geom_text(aes(label = Research.Area), hjust = 0, vjust = 0, size = 4, color = "black") +
theme(legend.direction = "horizontal", legend.position = "bottom") +
#  coord_cartesian(xlim = c(0.0,0.026), ylim = c(0.0,0.41)) + #
labs(x = "Coherence of research area", y = "Diversity  of research area") +
facet_wrap(~ P, nrow=2)
############################################################################
# Preamble
############################################################################
source("C:/Users/Admin/R_functions/preamble.R")
# Extra functions
source("00_functions.R")
library(bibliometrix)   ### load bibliometrix package: http:\\www.bibliometrix.org
library(stringr)
library(xtable)
library(stargazer)
library(DescTools) # For StringCap
library(igraph)
#### General: Put in less colsep!
# \setlength\tabcolsep{1pt}
# Do that in latex!
############################################################################
# Corpus Inspection
############################################################################
rm(list=ls())
M <- readRDS("temp/M_polish.RDS")
C <- readRDS("temp/C_polish.RDS")
### Some checkups
x <- C %>%
filter(book == T) %>%
arrange(desc(TC)) %>%
select(AU, JI, PY, com, TC, institution, dgr.int)
y <- C %>% group_by(com) %>% summarise(n = n(), n.book = sum(book), n.inst = sum(institution)) %>% ungroup() %>%
mutate(book.rel = n.book / n, inst.rel = n.inst / n)
z <- C %>%
filter(book == T) %>%
arrange(com, desc(TC)) %>%
group_by(com) %>% slice(1:10) %>% ungroup() %>%
select(com, AU, JI, PY, TC, institution, dgr.int)
C %>%
filter(PY >= 1980 & PY <= 2015 ) %>%
group_by(PY, book) %>% summarise(n = n(), TC.year = mean(TC.year)) %>%
arrange(PY) %>%
ggplot(aes(x = PY, y = TC.year, col = book) ) +
geom_line(size = 1)
C %>%
filter(PY >= 1980 & PY <= 2015 ) %>%
group_by(PY, book) %>% summarise(n = n(), TC = mean(TC)) %>%
arrange(PY) %>%
ggplot(aes(x = PY, y = TC, col = book) ) +
geom_line(size = 1)
C %>%
filter(PY >= 1980 & PY <= 2015 ) %>%
group_by(PY) %>% summarise(n = n(), n.book = sum(book)) %>%
mutate(rel = n.book / n) %>%
arrange(PY) %>%
ggplot(aes(x = PY, y = rel) ) +
geom_line(size = 1)
### OECD
oecd <- C %>%
filter(AU == "Oecd")
oecd %>%
group_by(com) %>%
count(sort = TRUE) %>%
ungroup() %>%
mutate(n = n / sum(n))
ec <- C %>%
filter(AU == "Ec")
cit_aut <- C %>%
group_by(AU) %>%
summarise(TC = sum(TC)) %>%
arrange(desc(TC))
############################################################################
# Corpus Inspection
############################################################################
#rm(list=ls())
source("00_parameters.r")
names.art <- readRDS("temp/names_art.RDS")
names.cit <- readRDS("temp/names_cit.RDS")
names.art <- bind_cols(com.art = names.art, names.art = com.names.bib.short)
names.cit <- bind_cols(com.cit = names.cit, names.cit = com.names.cit.short)
el <- readRDS("temp/cit_el_final.RDS") %>%
left_join(names.art, by = "com.art") %>%
left_join(M %>% select(SR, AU1), by = c("art" = "SR")) %>%
rename(AU.art = AU1) %>%
left_join(names.cit, by = "com.cit") %>%
left_join(C %>% select(cit, AU), by = "cit") %>%
rename(AU.cit = AU)
oecd %>%
group_by(com) %>%
count(sort = TRUE) %>%
ungroup() %>%
mutate(n = n / sum(n))
names.cit
com.names.cit.long
el %>%
filter(grepl("OECD", cit)) %>%
group_by(names.art) %>%
count(sort = TRUE)
el %>%
filter(grepl("OECD", cit)) %>%
group_by(names.art) %>%
count(sort = TRUE) %>%
ungroup() %>%
mutate(n = n / sum(n))
el %>%
filter(grepl("OECD", cit)) %>%
group_by(names.art, PY.art) %>%
count(sort = TRUE) %>%
ungroup() %>%
fdg
el %>%
filter(grepl("OECD", cit)) %>%
group_by(names.art, PY.art) %>%
count(sort = TRUE) %>%
ungroup()
el %>%
filter(grepl("OECD", cit)) %>%
group_by(PY.art) %>%
count(sort = TRUE) %>%
ungroup() %>%
arrange(PY.art)
el %>%
filter(grepl("OECD", cit)) %>%
group_by(PY.art) %>%
count(sort = TRUE) %>%
ungroup() %>%
arrange(PY.art) %>%
ggplot(aes(x = PY.art, y = n) ) +
geom_line()
el %>%
filter(grepl("OECD", cit)) %>%
group_by(PY.art) %>%
count(sort = TRUE) %>%
ungroup() %>%
arrange(desc(PY.art))
t <- readRDS("temp/el_2m_top.RDS")
names.t <- t %>%
distinct(topic) %>%
arrange(topic) %>%
bind_cols(topic.name = top.names.short)
t<- t %>%
left_join(names.t)
t.y <- t %>%
group_by(PY, topic.name) %>%
summarise(weight = mean(weight)) %>% ungroup() %>%
arrange(PY, desc(weight)) %>%
group_by(PY) %>%
slice(1:2)
t %>%
filter(SR %in%  (el %>% filter(grepl("OECD", cit)) %>% pull(art)) ) %>%
group_by(topic.name) %>%
summarise(weight = mean(weight)) %>% ungroup() %>%
arrange(desc(weight))
M %>% filter(SR %in% (M.old %>% filter(grepl("OECD", AB, ignore.case = TRUE)) %>% pull(SR)) ) %>%
group_by(AU1) %>%
count(sort = TRUE) %>%
ungroup() %>%
slice(1:20)
M.old <- readRDS("temp/M_final.RDS")
t %>%
filter(SR %in%  (M.old %>% filter(grepl("OECD", AB, ignore.case = TRUE)) %>% pull(SR)) ) %>%
filter(PY >= 2015) %>%
group_by(topic.name) %>%
summarise(weight = mean(weight)) %>% ungroup() %>%
arrange(desc(weight))
el %>% filter(grepl("OECD", cit)) %>%
group_by(AU.art) %>%
count(sort = TRUE) %>%
ungroup() %>%
slice(1:20)
y <- C %>% group_by(com) %>% summarise(n = n(), n.book = sum(book), n.inst = sum(institution)) %>% ungroup() %>%
mutate(book.rel = n.book / n, inst.rel = n.inst / n)
View(y)
com.names.cit.short
View(y)
View(C)
C %>% group_by(com) %>% summarise(n = n(),
books = sum(book),
books.rel = sum(book) / n())
C %>% summarise(n = n(), books = sum(book), books.rel = sum(book) / n())
C %>% summarise(n = n(), books = sum(book), books.rel = sum(book) / n(),
TC = sum(TC), TC.book = sum(TC * book), TC.book.rel = sum(TC * book) / sum(TC))
C %>% summarise(n = n(), books = sum(book), books.rel = sum(book) / n(),
TC = sum(TC), TC.book = sum( (TC * book) ), TC.book.rel = sum(TC * book) / sum(TC))
C %>%
group_by(book) %>%
summarise(n = n(), TC = sum(TC))
C %>%
group_by(book) %>%
summarise(n = n(), TC = sum(TC)) %>%
ungroup() %>%
mutate(n.rel = n / sum(n), TC.rel = TC / sum(TC))
View(y)
View(el)
rm(list=ls())
source("00_parameters.R")
com <- readRDS("temp/art_com_div_ext.RDS") %>% select(com, P, coh.ext, div.ext)
library(tidyr)
com2 <- com %>%
gather(variable, value, -(com:P)) %>%
unite(temp, P, variable) %>%
spread(temp, value)
com2 %<>% mutate(com = c(com.names.bib.short, "all"))
com2 %>% xtable(caption = "Network of Research Areas: Coherence and Diversity over time", #
label ="tab:stats_period_ext", digits = 3, align="LXR{0.75cm}R{0.75cm}R{0.75cm}R{0.75cm}R{0.75cm}R{0.75cm}R{0.75cm}R{0.75cm}R{0.75cm}R{0.75cm}") %>%
print.xtable(type="latex", file="output/stats_period_ext.tex", include.rownames=F, booktabs=T, #
table.placement="htbp!", tabular.environment="tabularx", width="\\textwidth", size="\\small", caption.placement="top", #
add.to.row = list(list(-1,nrow(.)),
c(" & \\multicolumn{2}{c}{1980-1989} &
\\multicolumn{2}{c}{1990-1999} &
\\multicolumn{2}{c}{2000-2009} &
\\multicolumn{2}{c}{after 2010} &
\\multicolumn{2}{c}{All Periods}  \\\\
\\cmidrule(rl){2-3} \\cmidrule(rl){4-5} \\cmidrule(rl){6-7} \\cmidrule(rl){8-9} \\cmidrule(rl){10-11}",
"\\midrule  \\multicolumn{11}{L{14cm}}{{\\tiny \\textbf{Note: } This table reports our measures for coherence and specialization of the clusters of research areas, and their development over time. In detail, it reports the whitin-cluster density, the between cluster density, and the GINI coefficient of the edgeweights from every cluster to the remaining ones. P1:1980-1989, P2:1990-1999, P3:2000-2009, P4:2010-2017.}} \\\\") ) )
rm(list=ls())
source("00_parameters.R")
com <- readRDS("temp/art_com_div_int.RDS") %>% select(com, P, coh.int, div.int)
library(tidyr)
com2 <- com %>%
gather(variable, value, -(com:P)) %>%
unite(temp, P, variable) %>%
spread(temp, value)
com2 %<>% mutate(com = c(com.names.bib.short, "all"))
com2 %>% xtable(caption = "Network of Research Areas: Internal Coherence and Diversity over time (2-Mode)", #
label ="tab:stats_period_int", digits = 3, align="LXR{0.75cm}R{0.75cm}R{0.75cm}R{0.75cm}R{0.75cm}R{0.75cm}R{0.75cm}R{0.75cm}R{0.75cm}R{0.75cm}") %>%
print.xtable(type="latex", file="output/stats_period_int.tex", include.rownames=F, booktabs=T, #
table.placement="htbp!", tabular.environment="tabularx", width="\\textwidth", size="\\small", caption.placement="top", #
add.to.row = list(list(-1,nrow(.)),
c(" & \\multicolumn{2}{c}{1980-1989} &
\\multicolumn{2}{c}{1990-1999} &
\\multicolumn{2}{c}{2000-2009} &
\\multicolumn{2}{c}{after 2010} &
\\multicolumn{2}{c}{All Periods}  \\\\
\\cmidrule(rl){2-3} \\cmidrule(rl){4-5} \\cmidrule(rl){6-7} \\cmidrule(rl){8-9} \\cmidrule(rl){10-11}",
"\\midrule  \\multicolumn{11}{L{14cm}}{{\\tiny \\textbf{Note: } This table reports our measures for coherence and specialization of the clusters of research areas, and their development over time. In detail, it reports the whitin-cluster density, the between cluster density, and the GINI coefficient of the edgeweights from every cluster to the remaining ones. P1:1980-1989, P2:1990-1999, P3:2000-2009, P4:2010-2017.}} \\\\") ) )
############################################################################
# Preamble
############################################################################
source("C:/Users/Admin/R_functions/preamble.R")
# Extra functions
source("00_functions.R")
library(bibliometrix)   ### load bibliometrix package: http:\\www.bibliometrix.org
library(stringr)
library(xtable)
library(stargazer)
library(DescTools) # For StringCap
library(igraph)
#### General: Put in less colsep!
# \setlength\tabcolsep{1pt}
# Do that in latex!
############################################################################
# Corpus Inspection
############################################################################
rm(list=ls())
M <- readRDS("temp/M_polish.RDS")
C <- readRDS("temp/C_polish.RDS")
### Some checkups
x <- C %>%
filter(book == T) %>%
arrange(desc(TC)) %>%
select(AU, JI, PY, com, TC, institution, dgr.int)
y <- C %>% group_by(com) %>% summarise(n = n(), n.book = sum(book), n.inst = sum(institution)) %>% ungroup() %>%
mutate(book.rel = n.book / n, inst.rel = n.inst / n)
C %>%
group_by(book) %>%
summarise(n = n(), TC = sum(TC)) %>%
ungroup() %>%
mutate(n.rel = n / sum(n), TC.rel = TC / sum(TC))
z <- C %>%
filter(book == T) %>%
arrange(com, desc(TC)) %>%
group_by(com) %>% slice(1:10) %>% ungroup() %>%
select(com, AU, JI, PY, TC, institution, dgr.int)
C %>%
filter(PY >= 1980 & PY <= 2015 ) %>%
group_by(PY, book) %>% summarise(n = n(), TC.year = mean(TC.year)) %>%
arrange(PY) %>%
ggplot(aes(x = PY, y = TC.year, col = book) ) +
geom_line(size = 1)
C %>%
filter(PY >= 1980 & PY <= 2015 ) %>%
group_by(PY, book) %>% summarise(n = n(), TC = mean(TC)) %>%
arrange(PY) %>%
ggplot(aes(x = PY, y = TC, col = book) ) +
geom_line(size = 1)
C %>%
filter(PY >= 1980 & PY <= 2015 ) %>%
group_by(PY) %>% summarise(n = n(), n.book = sum(book)) %>%
mutate(rel = n.book / n) %>%
arrange(PY) %>%
ggplot(aes(x = PY, y = rel) ) +
geom_line(size = 1)
### OECD
oecd <- C %>%
filter(AU == "Oecd")
oecd %>%
group_by(com) %>%
count(sort = TRUE) %>%
ungroup() %>%
mutate(n = n / sum(n))
ec <- C %>%
filter(AU == "Ec")
cit_aut <- C %>%
group_by(AU) %>%
summarise(TC = sum(TC)) %>%
arrange(desc(TC))
############################################################################
# Corpus Inspection
############################################################################
#rm(list=ls())
source("00_parameters.r")
names.art <- readRDS("temp/names_art.RDS")
names.cit <- readRDS("temp/names_cit.RDS")
names.art <- bind_cols(com.art = names.art, names.art = com.names.bib.short)
names.cit <- bind_cols(com.cit = names.cit, names.cit = com.names.cit.short)
el <- readRDS("temp/cit_el_final.RDS") %>%
left_join(names.art, by = "com.art") %>%
left_join(M %>% select(SR, AU1), by = c("art" = "SR")) %>%
rename(AU.art = AU1) %>%
left_join(names.cit, by = "com.cit") %>%
left_join(C %>% select(cit, AU), by = "cit") %>%
rename(AU.cit = AU)
el %>%
filter(grepl("OECD", cit)) %>%
group_by(names.art) %>%
count(sort = TRUE) %>%
ungroup() %>%
mutate(n = n / sum(n))
el %>%
filter(grepl("OECD", cit)) %>%
group_by(PY.art) %>%
count(sort = TRUE) %>%
ungroup() %>%
arrange(desc(PY.art)) %>%
ggplot(aes(x = PY.art, y = n) ) +
geom_line()
el %>%
filter(grepl("OSLO MAN", cit)) %>%
group_by(names.art) %>%
count(sort = TRUE)
el %>%
filter(grepl("^EC ", cit)) %>%
group_by(names.art) %>%
count(sort = TRUE)
el %>%
filter(grepl("GREEN PAP", cit)) %>%
group_by(names.art) %>%
count(sort = TRUE)
el %>%
group_by(names.art) %>%
summarize(n = n(), books = sum(books), books.rel = sum(books) / n()) %>%
ungroup() %>%
arrange(desc(books.rel))
# books
el %>%
group_by(names.art) %>%
summarize(n = n(), books = sum(book), books.rel = sum(book) / n()) %>%
ungroup() %>%
arrange(desc(books.rel))
View(el)
#rm(list=ls())
source("00_parameters.r")
names.art <- readRDS("temp/names_art.RDS")
names.cit <- readRDS("temp/names_cit.RDS")
names.art <- bind_cols(com.art = names.art, names.art = com.names.bib.short)
names.cit <- bind_cols(com.cit = names.cit, names.cit = com.names.cit.short)
el <- readRDS("temp/cit_el_final.RDS") %>%
left_join(names.art, by = "com.art") %>%
left_join(M %>% select(SR, AU1), by = c("art" = "SR")) %>%
rename(AU.art = AU1) %>%
left_join(names.cit, by = "com.cit") %>%
left_join(C %>% select(cit, AU, book), by = "cit") %>%
rename(AU.cit = AU)
el %>%
filter(grepl("OECD", cit)) %>%
group_by(names.art) %>%
count(sort = TRUE) %>%
ungroup() %>%
mutate(n = n / sum(n))
el %>%
filter(grepl("OECD", cit)) %>%
group_by(PY.art) %>%
count(sort = TRUE) %>%
ungroup() %>%
arrange(desc(PY.art)) %>%
ggplot(aes(x = PY.art, y = n) ) +
geom_line()
el %>%
filter(grepl("OSLO MAN", cit)) %>%
group_by(names.art) %>%
count(sort = TRUE)
el %>%
filter(grepl("^EC ", cit)) %>%
group_by(names.art) %>%
count(sort = TRUE)
el %>%
filter(grepl("GREEN PAP", cit)) %>%
group_by(names.art) %>%
count(sort = TRUE)
# books
el %>%
group_by(names.art) %>%
summarize(n = n(), books = sum(book), books.rel = sum(book) / n()) %>%
ungroup() %>%
arrange(desc(books.rel))
setwd("C:/Users/Admin/OneDrive - Aalborg Universitet/01 - Teaching/Course - SDS/00_github/M1-2018/assignments/assignment_1/assignment_v2")
### Cleaning the workspace, meaning deleting all previously loaded data (optimal step)
rm(list=ls())
### Loading packages
library(tidyverse) # loads the whole tidyverse, including dplyr, readr, ggplot, etc
library(data.table) # loads the data.table package, in case you use the fread()
# Best thing to do: fread() from data.table
# header = TRUE tells fread that the first row should be interpreted as variable-name
# data.table = TRUE tells fread that it should not create a data.table (its own data format), but a dataframe instead
# check.names = TRUE will replace space in Variable names with . (because R doesnt like that)
cities_df <- fread("cities_df.csv", header = TRUE, check.names = TRUE, data.table = FALSE)
trips_df <- fread("trips_df.csv", header = TRUE, check.names = TRUE, data.table = FALSE)
### Inspect the data
# how dies the data look like? head() prints the first rows
head(cities_df)
# Best thing to do: fread() from data.table
# header = TRUE tells fread that the first row should be interpreted as variable-name
# data.table = TRUE tells fread that it should not create a data.table (its own data format), but a dataframe instead
# check.names = TRUE will replace space in Variable names with . (because R doesnt like that)
cities_df <- fread("cities_df.csv", header = TRUE, check.names = TRUE, data.table = FALSE) %>% as_data_frame()
trips_df <- fread("trips_df.csv", header = TRUE, check.names = TRUE, data.table = FALSE) %>% as_data_frame()
# Best thing to do: fread() from data.table
# header = TRUE tells fread that the first row should be interpreted as variable-name
# data.table = TRUE tells fread that it should not create a data.table (its own data format), but a dataframe instead
# check.names = TRUE will replace space in Variable names with . (because R doesnt like that)
cities_df <- fread("cities_df.csv", header = TRUE, check.names = TRUE, data.table = FALSE) %>% data_frame()
# Best thing to do: fread() from data.table
# header = TRUE tells fread that the first row should be interpreted as variable-name
# data.table = TRUE tells fread that it should not create a data.table (its own data format), but a dataframe instead
# check.names = TRUE will replace space in Variable names with . (because R doesnt like that)
cities_df <- fread("cities_df.csv", header = TRUE, check.names = TRUE, data.table = FALSE) %>% as_tibble()
trips_df <- fread("trips_df.csv", header = TRUE, check.names = TRUE, data.table = FALSE) %>% as_tibble()
### Inspect the data
# how dies the data look like? head() prints the first rows
head(cities_df)
head(trips_df)
### Lets only look at cities:
glimpse(cities_df)
### set working directory
# This will set your working rirectory to the place where the scipt is. Note: Only relevant for
# r-script files ()endlng with .r). R-Notebooks ()ending with .rmd) by default take
setwd("folder1/foler2/final_folder") # Change that. Copy&Past your directory path, for example ""
### Cleaning the workspace, meaning deleting all previously loaded data (optimal step)
rm(list=ls())
### Installing packages: If you did not install the packages, uncomment (remove the leading #) the following lines and run
# install.packages("tidyverse")
# install.packages("data.table")
### Loading packages
library(tidyverse) # loads the whole tidyverse, including dplyr, readr, ggplot, etc
library(data.table) # loads the data.table package, in case you use the fread()
### Loading data
# Necessary: the datafiles you find in the assignment folder have to be placed in the same folder as this script file.
# Best thing to do: fread() from data.table
# header = TRUE tells fread that the first row should be interpreted as variable-name
# data.table = TRUE tells fread that it should not create a data.table (its own data format), but a dataframe instead
# check.names = TRUE will replace space in Variable names with . (because R doesnt like that)
cities_df <- fread("cities_df.csv", header = TRUE, check.names = TRUE, data.table = FALSE) %>% as_tibble()
trips_df <- fread("trips_df.csv", header = TRUE, check.names = TRUE, data.table = FALSE) %>% as_tibble()
### Inspect the data
# how dies the data look like? head() prints the first rows
head(cities_df)
head(trips_df)
# variable names are a mix of capital letters, and small letters. Lets make them all small.
colnames(trips_df) <- tolower(colnames(trips_df))
colnames(cities_df) <- tolower(colnames(cities_df))
# Further, we see that for some reasons some variable names (eg., country) appear more than once
# Let's throw them out
cities_df <- cities_df[,!duplicated(colnames(cities_df))]
### Lets only look at cities:
glimpse(cities_df)
